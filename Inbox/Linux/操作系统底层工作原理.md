
# CPU发展关键技术
| 关键技术 | 时间 | 描述 |
| --- | --- | --- |
| 指令换成 | 1982 | 预读多条指令 |
| 数据缓存 | 1985 | 预读一定长度的数据 |
| 流水线 | 1989 | 一条指令被拆分由多个单元协同处理 |
| 多流水线 | 1993 | 多运算单元多流水线并行处理 |
| 乱序+分支预测 | 1995 | 充分利用不同组件协同处理 |
| 超线程 | 2002 | 引入多组前端部件共享执行引擎 |
| 多核处理器 | 2006 | 取消超线程，降低时钟频率，改用多核心 |
| 多核超线程 | 2008 | 重新引入超线程技术 |


# KLT和ULT

KLT：内核级线程
- 线程管理的所有工作（创建和撤销）由操作系统内核完成
- 操作系统内核提供一个应用程序设计接口API，供开发者使用KLT

纯内核级别线程的特点：
1. 进程中的一个线程被阻塞，内核能调度同一进程的其他线程占有处理器运行
2. 多处理器环境中，内核能同时调度同一进程的多线程，将这些线程映射到不同的处理器核心上，提高进程的执行效率
3. 应用程序线程在用户态运行，线程调度和管理在内核实现。线程调度时，控制权从一个线程改变到另一线程，需要模式切换，系统开销较大

ULT：用户级别线程
- 用户空间运行线程库，任何应用程序都可以通过使用线程库被设计成多线程程序。线程库是用于用户级线程管理的一个例程包，它提供多线程应用程序的开发和运行支撑环境，包含：用于创建和销毁线程的代码、在线程间传递数据和消息的代码、调度线程执行的代码以及保存和恢复线程上下文的代码
- 所以线程的创建，消息传递，调度，保存/恢复上下文都由线程库来完成。内核感知不到多线程的存在。

纯用户级线程的特点：
1. 线程切换不需要内核模式，能节省模式切换开销和内核资源
2. 允许进程按照特定的需要选择不同的调度算法来调度线程。调度算法需要自己实现
3. 由于不需要内核 支持，可以跨OS运行
4. 不能利用多核处理器的特点，OS调度进程，每个进程仅有一个ULT能执行
5. 一个ULT阻塞，将导致整个进程的阻塞


# 内核空间和用户空间

在 CPU 的所有指令中，有些指令是非常危险的，如果错用，将导致系统崩溃，比如清内存、设置时钟等。如果允许所有的程序都可以使用这些指令，那么系统崩溃的概率将大大增加。
所以，CPU 将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通应用程序只能使用那些不会造成灾难的指令。比如 Intel 的 CPU 将特权等级分为 4 个级别：Ring0~Ring3。
其实 Linux 系统只使用了 Ring0 和 Ring3 两个运行级别(Windows 系统也是一样的)。当进程运行在 Ring3 级别时被称为运行在用户态，而运行在 Ring0 级别时被称为运行在内核态。
以32位操作系统4G大小的内存空间为例：
![](https://vitahlin.oss-cn-shanghai.aliyuncs.com/images/blog/2023/202302151553609.png)


Linux为内核代码和数据结构预留了几个页框，这些页永远不会被转出到磁盘上。从 0x00000000 到 0xc0000000(PAGE_OFFSET) 的线性地址可由用户代码和内核代码进行引用(即用户空间)。从0xc0000000(PAGE_OFFSET)到 0xFFFFFFFFF的线性地址只能由内核代码进行访问(即内核空间)。内核代码及其数据结构都必须位于这 1 GB的地址 空间中，但是对于此地址空间而言，更大的消费者是物理地址的虚拟映射。
这意味着在 4 GB 的内存空间中，只有 3 GB 可以用于用户应用程序。进程与线程只能 运行在用户方式(usermode)或内核方式(kernelmode)下。用户程序运行在用户方式 下，而系统调用运行在内核方式下。在这两种方式下所用的堆栈不一样：用户方式下用的是 一般的堆栈(用户空间的堆栈)，而内核方式下用的是固定大小的堆栈(内核空间的对战，一 般为一个内存页的大小)，即每个进程与线程其实有两个堆栈，分别运行与用户态与内核态。

## 如何从用户空间进入内核空间

其实 **所有的系统资源管理都是在内核空间中完成的。**

比如读写磁盘文件，分配回收内存，从网络接口读写数据等等。我们的应用程序是无法直接进行这样的操作的。但是我们可以通过内核提供的接口来完成这样的任务。
比如应用程序要读取磁盘上的一个文件，它可以向内核发起一个 "系统调用" 告诉内核："我要读取磁盘上的某某文件"。其实就是通过一个特殊的指令让进程从用户态进入到内核态(到了内核空间)，在内核空间中，CPU 可以执行任何的指令，当然也包括从磁盘上读取数据。具体过程是先把数据读取到内核空间中，然后再把数据拷贝到用户空间并从内核态切换到用户态。此时应用程序已经从系统调用中返回并且拿到了想要的数据，可以开开心心的往下执行了。
简单说就是应用程序把高科技的事情(从磁盘读取文件)外包给了系统内核，系统内核做这些事情既专业又高效。

下图简明的描述了**用户态与内核态之间的转换，概括的说，有3种方式：系统调用、软中断和硬件中断。**

![image.png](https://vitahlin.oss-cn-shanghai.aliyuncs.com/images/blog/2023/202302151555305.png)



# 虚拟机指令集架构
指令集架构的维基说明：[https://zh.wikipedia.org/wiki/指令集架構](https://zh.wikipedia.org/wiki/指令集架構)
主要分两种：

1. 栈指令集架构
2. 寄存器指令集架构

## 栈指令集架构

1. 设计和实现更简单,适用于资源受限的系统;
2. 避开了寄存器的分配难题：使用零地址指令方式分配;
3. 指令流中的指令大部分是零地址指令，其执行过程依赖与操作栈,指令集更小，编译器容易实现；
4. 不需要硬件支持,可移植性更好,更好实现跨平台。

## 寄存器指令集架构

1. 典型的应用是x86的二进制指令集：比如传统的PC以及Android的Davlik虚拟机。
2. 指令集架构则完全依赖硬件,可移植性差。
3. 性能优秀和执行更高效。
4. 花费更少的指令去完成一项操作。
5. 在大部分情况下,基于寄存器架构的指令集往往都以一地址指令、二地址指令和三 地址指令为主,而基于栈式架构的指令集却是以零地址指令为主。

Java符合典型的栈指令集架构特征，像Python、Go都属于这种架构。


# CPU缓存架构
常见的为三级缓存结构

1. L1 Cache，分为数据缓存和指令缓存，逻辑核独占
2. L2 Cache，物理核独占，逻辑核共享
3. L3 Cache，所有物理核共享

存储空间大小：内存>L3>L2>L1>寄存器
存储速度快慢：寄存器 > L1 > L2 > L3 > 内存

缓存由最小的存储区块-**缓存行**(cache line)组成，缓存行大小通常为64byte。

缓存架构图如下：
![image.png](https://vitahlin.oss-cn-shanghai.aliyuncs.com/images/blog/2023/202302151556839.png)



## CPU读取存储器数据过程

1. CPU要取寄存器的值，只需要一步：直接读取
2. CPU要读取L1 cache 的值，需要1-3步：把cache行锁住，把某个数据拿来，解锁，如果没锁住就慢了
3. CPU要取L2 cache的某个值，先要到L1 cache里取，L1当中不存在，在L2里，L2开始加锁，加 锁以后，把L2里的数据复制到L1，再执行读L1的过程，上面的3步，再解锁。
4. CPU取L3 cache的也是一样，只不过先由L3复制到L2，从L2复制到L1，从L1到CPU。
5. CPU取内存则最复杂：通知内存控制器占用总线带宽，通知内存加锁，发起内存读请求，等待回应，回应数据保存到L3(如果没有就到L2)，再从L3/2到L1，再从L1到CPU，之后解除总线锁定。

## CPU的局部性原理

时间局部性：如果一个信息项正在被访问，那么它近期内很可能还会被再次访问。比如，循环，递归，方法的反复调用等。
空间局部性：如果一个存储器的位置被引用，那么将来它附近的位置也会被引用。比如顺序执行的代码、连续创建的两个对象，数组等。

空间局部性例子：
```java
public class CpuSpatialLocality {

    private static final int REPEAT_COUNT = 100;
    private static final int DIMENSION_1 = 1024 * 1024;
    private static final int DIMENSION_2 = 6;
    private static long[][] longs;

    public static void main(String[] args) {
        longs = new long[DIMENSION_1][];

        // 创建的时候，可以理解为，矩阵行为6，列为1024*1024
        for (int i = 0; i < DIMENSION_1; i++) {
            longs[i] = new long[DIMENSION_2];
            for (int j = 0; j < DIMENSION_2; j++) {
                longs[i][j] = 1;
            }
        }
        System.out.println("初始化完毕...");


        long sum = 0L;
        long start = System.currentTimeMillis();
        for (int r = 0; r < REPEAT_COUNT; r++) {
            for (int i = 0; i < DIMENSION_1; i++) {
                for (int j = 0; j < DIMENSION_2; j++) {
                    sum += longs[i][j];
                }
            }
        }
        System.out.println("spend time1:" + (System.currentTimeMillis() - start));
        System.out.println("sum1:" + sum);

        sum = 0L;
        start = System.currentTimeMillis();
        for (int r = 0; r < REPEAT_COUNT; r++) {
            for (int j = 0; j < DIMENSION_2; j++) {
                for (int i = 0; i < DIMENSION_1; i++) {
                    sum += longs[i][j];
                }
            }
        }
        System.out.println("spend time2:" + (System.currentTimeMillis() - start));
        System.out.println("sum2:" + sum);
    }
}
```
执行结果：
```shell
初始化完毕...
spend time1:1818
sum1:629145600
spend time2:4315
sum2:629145600
```

可以看到2的时间比1久的多，因为数组初始化的时候顺序可以理解为行为6列为 1024\*1024的矩阵，1中的取值更符合空间局部性原则。
